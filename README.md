# Character-Recognition-and-Extraction-using-OpenCV-and-Pytesseract


The project “Character Recognition and Extraction using OpenCV and Pytesseract” is designed to detect, extract, and digitize printed English text from both images and videos. It integrates the power of computer vision (via OpenCV) with Optical Character Recognition (via Tesseract OCR) to recognize and convert text into a machine-readable format. The system accepts various inputs such as scanned images, screenshots, or video files. It processes visual content by applying essential preprocessing steps like grayscale conversion, thresholding, resizing, and noise reduction to enhance text clarity. The OCR engine then analyzes the processed frames or images, detects characters, and extracts the text accurately along with their positions for visualization.

In addition to visual text recognition, the project also supports speech-to-text transcription from video files. It uses MoviePy to extract audio, splits long recordings into smaller segments using Pydub, and transcribes the spoken content using Google’s Speech Recognition API. The transcribed data is then compiled into a text file, offering a complete textual representation of both spoken and visual data. Overall, this system can be applied in real-world scenarios such as digitizing printed content, summarizing lectures or tutorials, and aiding in accessibility for educational or professional purposes. It showcases modular design, efficient preprocessing, and multimodal data handling — all of which make it a practical and versatile AI application.
